{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lesser-adelaide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                           \\n, resume_model1='/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model1_100.pth.tar'                            , resume_model2='/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model2_100.pth.tar'                            , resume_model1=''                            , resume_model2='' \\n                           \\n                           \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from os.path import exists, join, split\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "  from modules import batchnormsync\n",
    "except ImportError:\n",
    "  pass\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data_transforms as transforms\n",
    "from utils import *\n",
    "from Par_CRF import apply_dcrf_par\n",
    "from Par_CRF import apply_dcrf_single\n",
    "from Par_CRF import apply_dcrf\n",
    "from Par_CRF import save_compute_crf\n",
    "from DataClass import *\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "FORMAT = \"[%(asctime)-15s %(filename)s:%(lineno)d %(funcName)s] %(message)s\"\n",
    "logging.basicConfig(format=FORMAT)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def validate(val_loader, model, epoch, doc_directory, args, print_freq=10):\n",
    "        batch_time = AverageMeter()\n",
    "\n",
    "        DOC=Trackometer(epoch)\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        for i, (input, GT_label, pseudolabels, name) in tqdm(enumerate(val_loader)):\n",
    "            #====================================================================================================================\n",
    "            #       Get Image Names, Check Sizes\n",
    "            #====================================================================================================================\n",
    "            size=GT_label.shape[2]\n",
    "            for target in pseudolabels:\n",
    "                assert target.shape==GT_label.shape\n",
    "\n",
    "            #Get image name without path\n",
    "            imname = [(path.split('/')[-1])[:-4] + '.png' for path in name]\n",
    "            #====================================================================================================================\n",
    "            #make target float and normalize to range [0,1] for each pixel\n",
    "            if torch.max(GT_label)!=0:\n",
    "                GT_label=GT_label.float()/torch.max(GT_label).item()\n",
    "            else:\n",
    "                GT_label=GT_label.float()\n",
    "\n",
    "            #input = input.cuda()\n",
    "            input = input.cuda()\n",
    "\n",
    "            input_var = torch.autograd.Variable(input).cuda()\n",
    "            GT_label_var = torch.autograd.Variable(GT_label).cuda()\n",
    "            #input_var = torch.autograd.Variable(input)\n",
    "            #GT_label_var = torch.autograd.Variable(GT_label)\n",
    "\n",
    "            #====================================================================================================================\n",
    "            #       Compute Output, normalize it. Optionally apply DCRF\n",
    "            #====================================================================================================================\n",
    "            # compute output\n",
    "            output = model(input_var)[0]\n",
    "\n",
    "            m=torch.nn.Softmax(dim=1)\n",
    "            sal_pred=m(output)\n",
    "            if args.DCRF:\n",
    "                sal_pred=apply_dcrf(sal_pred, name, Color=args.DCRF=='Color' or args.DCRF=='color')\n",
    "            else:\n",
    "                 sal_pred=sal_pred[:, 0, :, :]\n",
    "\n",
    "            #====================================================================================================================\n",
    "            #       Update Documentation, Print status in terminal (in respective iterations), save maps (in respective epochs)\n",
    "            #====================================================================================================================\n",
    "            DOC.update(sal_pred, GT_label_var, [], [])\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            FreqPrint=len(val_loader)//print_freq\n",
    "            if FreqPrint<1:\n",
    "                FreqPrint=1\n",
    "            if i % (FreqPrint) == 0:\n",
    "                logger.info('Test: [{0}/{1}]\\t'\n",
    "                            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                            'MAE GT {MAE_GT.val:.4f} ({MAE_GT.avg:.4f})\\t'\n",
    "                            'F-Score GT {F_GT.val:.3f} ({F_GT.avg:.3f})'\n",
    "                            .format(i, len(val_loader), batch_time=batch_time, MAE_GT=DOC.L1_GT, F_GT=DOC.F_GT))\n",
    "\n",
    "        logger.info('\\n\\nValidation Epoch {}:\\t\\tMAE (GT) = {:.1f} %\\t\\tF-score (GT) = {:.1f} %\\n'.format(epoch, DOC.L1_GT.avg*100, DOC.F_GT.avg*100))\n",
    "\n",
    "        f=open(doc_directory + \"loss_val.txt\", \"a\")\n",
    "        f.write('{}\\t{}\\t{}\\n'.format(epoch, DOC.L1_GT.avg, DOC.F_GT.avg))\n",
    "        f.close()\n",
    "\n",
    "        return DOC.F_GT.avg, DOC.L1_GT.avg\n",
    "\n",
    "def eval_train(train_loader, model, epoch, doc_directory, args, discretization_threshold, refined_labels_directory=None, iter_size=5,\n",
    "           print_freq=10, TrainMapsOut=False,mva_preds=None,image2indx=None):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    DOC=Trackometer(epoch)\n",
    "    if TrainMapsOut:\n",
    "        DOC_plain = Trackometer(epoch)\n",
    "        DOC_CRF = Trackometer(epoch)\n",
    "        DOC_MVA = Trackometer(epoch)\n",
    "\n",
    "    Disc_Thr = discretization_threshold\n",
    "\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    output_shape = mva_preds.shape\n",
    "    raw_preds  = torch.zeros((output_shape[0],2,output_shape[1],output_shape[2]))\n",
    "    gt_targets =  torch.zeros((mva_preds.shape))\n",
    "    pseudo_targets =  torch.zeros((mva_preds.shape))\n",
    "\n",
    "    all_losses= torch.zeros(len(train_loader.dataset))\n",
    "    with torch.no_grad():\n",
    "        for i, (index, Data) in tqdm(enumerate(train_loader)):\n",
    "            #====================================================================================================================\n",
    "            #       Get time, Image Names, Check Sizes\n",
    "            #       Normalize Labels, create variables and put them on cuda\n",
    "            #====================================================================================================================\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            #initialize batch data\n",
    "            batch_data=BatchData(Data, active=True)\n",
    "            #check dimensions of labels\n",
    "            batch_data.check_dimension()\n",
    "            #Make GT label and pseudolabels float and normalize to range [0,1]\n",
    "            batch_data.normalize_labels()\n",
    "            #Push input to cuda. Create Variables for input and labels.\n",
    "            #batch_data.create_vars_on_cuda()\n",
    "            batch_data.create_vars_on_cuda()\n",
    "\n",
    "            #====================================================================================================================\n",
    "            #       Compute Output, normalize it. Optionally apply DCRF\n",
    "            #====================================================================================================================\n",
    "            #compute saliency prediction, normalize with softmax. Optionally apply Threshold.\n",
    "            batch_data.compute_saliency(model, False)\n",
    "\n",
    "            #====================================================================================================================\n",
    "            #       If TrainMapsOut: Save Training Images (Before Optimizer Step!)\n",
    "            #====================================================================================================================\n",
    "            if TrainMapsOut:\n",
    "                m = torch.nn.Softmax(dim=1)\n",
    "                sal_pred_raw = m(batch_data.output)\n",
    "                gt_targets[image2indx(batch_data.names)] = batch_data.GT_label\n",
    "                pseudo_targets[image2indx(batch_data.names)] = batch_data.pseudolabels[0]\n",
    "                assert len(batch_data.pseudolabels) == 1, 'Only one map should be refined at a time in order to not lose information'\n",
    "                raw_preds[image2indx(batch_data.names)] = sal_pred_raw.detach().cpu()\n",
    "\n",
    "            #====================================================================================================================\n",
    "            #       Discretize Targets and apply 'soft thresholding' to saliency predictions.\n",
    "            #====================================================================================================================\n",
    "            #Discretize all pseudolabels and apply soft thresholing\n",
    "\n",
    "            batch_data.discretize_pseudolabels(Disc_Thr)\n",
    "\n",
    "            #=====================================================================================================================\n",
    "            #       Compute Loss, Gradient and perform optimizer Step.\n",
    "            #====================================================================================================================\n",
    "            #compute the loss (with asymmetries and all) and save to batch_active.loss\n",
    "            batch_data.compute_loss(mean_loss=False, beta=args.beta_sq)\n",
    "            loss=torch.mean(batch_data.loss)\n",
    "            \n",
    "            for b in range(len(index)):\n",
    "                 all_losses[index[b]]=batch_data.loss[b]\n",
    "            #====================================================================================================================\n",
    "            #       Update Documentation\n",
    "            #====================================================================================================================\n",
    "            DOC.update(batch_data.sal_pred, batch_data.GT_label_var, batch_data.sal_pred_list, batch_data.pseudolabels_var)\n",
    "            #losses is redundant with loss DOC.Loss. Kept for convenience.\n",
    "            losses.update(loss.data.item(), batch_data.input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            FreqPrint=len(train_loader)//print_freq\n",
    "            if FreqPrint<1:\n",
    "                FreqPrint=1\n",
    "            if i % (FreqPrint) == 0:\n",
    "                logger.info('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                             'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                             'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                             'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                             'L1 Loss GT {loss_L1_GT.val:.4f} ({loss_L1_GT.avg:.4f})\\t'\n",
    "                             .format(epoch,\n",
    "                                     i,\n",
    "                                     len(train_loader),\n",
    "                                     batch_time=batch_time,\n",
    "                                     data_time=data_time,\n",
    "                                     loss=losses,\n",
    "                                     loss_L1_GT=DOC.L1_GT,\n",
    "                                     ))\n",
    "\n",
    "    all_losses = (all_losses-all_losses.min())/(all_losses.max()-all_losses.min())\n",
    "    all_losses = all_losses.reshape(-1,1)\n",
    "    # fit a two-component GMM to the loss\n",
    "    gmm = GaussianMixture(n_components=2,max_iter=10,tol=1e-2,reg_covar=5e-4)\n",
    "    #gmm = BayesianGaussianMixture(n_components=2,max_iter=10,tol=1e-2,reg_covar=5e-4)\n",
    "    #pdb.set_trace()\n",
    "    gmm.fit(all_losses)\n",
    "    prob = gmm.predict_proba(all_losses)\n",
    "    prob = prob[:,gmm.means_.argmin()]\n",
    "\n",
    "    if TrainMapsOut:\n",
    "        assert refined_labels_directory is not None, 'Directory for output of refined Maps needs to be specified'\n",
    "        #Create Output Directories\n",
    "        path_train = refined_labels_directory\n",
    "        path_plain = join(path_train, 'PlainMaps/')\n",
    "        path_CRF = join(path_train, 'CRFMaps/')\n",
    "        path_MVA = join(path_train, 'MVAMaps/')\n",
    "        for path in  [path_train,path_plain,path_CRF,path_MVA]:\n",
    "            os.makedirs(path,exist_ok=True)\n",
    "        name = train_loader.dataset.image_list # the order is kept correctly, 0...2499\n",
    "\n",
    "        save_compute_crf(path_plain, path_CRF, path_MVA,\n",
    "                           name, gt_targets, pseudo_targets, raw_preds, mva_preds,\n",
    "                           image2indx,\n",
    "                           DOC_plain, DOC_CRF, DOC_MVA,\n",
    "                           args)\n",
    "\n",
    "        assert mva_preds.sum()!=0, 'mva_preds was not updated!?'\n",
    "\n",
    "        logger.info('\\n\\n\\nTraining Maps Extracted in this epoch {}. Results:\\n\\nPlain:{}\\nCRF:{}\\nMVA:{}'\\\n",
    "            .format(epoch, str(DOC_plain), str(DOC_CRF), str(DOC_MVA)))\n",
    "\n",
    "        DOC_plain.write_history(refined_labels_directory + \"Results_plain.txt\")\n",
    "        DOC_CRF.write_history(refined_labels_directory + \"Results_CRF.txt\")\n",
    "        DOC_MVA.write_history(refined_labels_directory + \"Results_MVA.txt\")\n",
    "\n",
    "    else:\n",
    "        DOC.write_history(doc_directory + \"loss_eval_train.txt\")\n",
    "\n",
    "    return prob\n",
    "\n",
    "\n",
    "def warmup(train_loader, model,  optimizer, epoch, doc_directory, args, discretization_threshold, refined_labels_directory=None, iter_size=5, print_freq=10, TrainMapsOut=False,mva_preds=None,image2indx=None):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    DOC=Trackometer(epoch)\n",
    "    if TrainMapsOut:\n",
    "        DOC_plain = Trackometer(epoch)\n",
    "        DOC_CRF = Trackometer(epoch)\n",
    "        DOC_MVA = Trackometer(epoch)\n",
    "\n",
    "    Disc_Thr = discretization_threshold\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    output_shape = mva_preds.shape\n",
    "    raw_preds  = torch.zeros((output_shape[0],2,output_shape[1],output_shape[2]))\n",
    "    gt_targets =  torch.zeros((mva_preds.shape))\n",
    "    pseudo_targets =  torch.zeros((mva_preds.shape))\n",
    "\n",
    "    for i, (index, Data) in tqdm(enumerate(train_loader)):\n",
    "        #====================================================================================================================\n",
    "        #       Get time, Image Names, Check Sizes\n",
    "        #       Normalize Labels, create variables and put them on cuda\n",
    "        #====================================================================================================================\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        #initialize batch data\n",
    "        batch_data=BatchData(Data, active=True)\n",
    "        #check dimensions of labels\n",
    "        batch_data.check_dimension()\n",
    "        #Make GT label and pseudolabels float and normalize to range [0,1]\n",
    "        batch_data.normalize_labels()\n",
    "        #Push input to cuda. Create Variables for input and labels.\n",
    "        #batch_data.create_vars_on_cuda()\n",
    "        batch_data.create_vars_on_cuda()\n",
    "\n",
    "        #====================================================================================================================\n",
    "        #       Compute Output, normalize it. Optionally apply DCRF\n",
    "        #====================================================================================================================\n",
    "        #compute saliency prediction, normalize with softmax. Optionally apply Threshold.\n",
    "\n",
    "        batch_data.compute_saliency(model, False)\n",
    "\n",
    "        #====================================================================================================================\n",
    "        #       If TrainMapsOut: Save Training Images (Before Optimizer Step!)\n",
    "        #====================================================================================================================\n",
    "        if TrainMapsOut:\n",
    "            m = torch.nn.Softmax(dim=1)\n",
    "            sal_pred_raw = m(batch_data.output)\n",
    "            gt_targets[image2indx(batch_data.names)] = batch_data.GT_label\n",
    "            pseudo_targets[image2indx(batch_data.names)] = batch_data.pseudolabels[0]\n",
    "            assert len(batch_data.pseudolabels) == 1, 'Only one map should be refined at a time in order to not lose information'\n",
    "            raw_preds[image2indx(batch_data.names)] = sal_pred_raw.detach().cpu()\n",
    "\n",
    "        #====================================================================================================================\n",
    "        #       Discretize Targets and apply 'soft thresholding' to saliency predictions.\n",
    "        #====================================================================================================================\n",
    "        #Discretize all pseudolabels and apply soft thresholing\n",
    "        batch_data.discretize_pseudolabels(Disc_Thr)\n",
    "\n",
    "        #=====================================================================================================================\n",
    "        #       Compute Loss, Gradient and perform optimizer Step.\n",
    "        #====================================================================================================================\n",
    "        #compute the loss (with asymmetries and all) and save to batch_active.loss\n",
    "        batch_data.compute_loss(beta=args.beta_sq)\n",
    "        loss = batch_data.loss\n",
    "\n",
    "        #pass iter_size batches before updating grad\n",
    "        if i%iter_size==0:\n",
    "            optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if i%iter_size==iter_size-1:\n",
    "            optimizer.step()\n",
    "\n",
    "        #====================================================================================================================\n",
    "        #       Update Documentation\n",
    "        #====================================================================================================================\n",
    "        DOC.update(batch_data.sal_pred, batch_data.GT_label_var, batch_data.sal_pred_list, batch_data.pseudolabels_var)\n",
    "        #losses is redundant with loss DOC.Loss. Kept for convenience.\n",
    "        losses.update(loss.data.item(), batch_data.input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        FreqPrint=len(train_loader)//print_freq\n",
    "        if FreqPrint<1:\n",
    "            FreqPrint=1\n",
    "        if i % (FreqPrint) == 0:\n",
    "            logger.info('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                         'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                         'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                         'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                         'L1 Loss GT {loss_L1_GT.val:.4f} ({loss_L1_GT.avg:.4f})\\t'\n",
    "                         .format(epoch,\n",
    "                                 i,\n",
    "                                 len(train_loader),\n",
    "                                 batch_time=batch_time,\n",
    "                                 data_time=data_time,\n",
    "                                 loss=losses,\n",
    "                                 loss_L1_GT=DOC.L1_GT,\n",
    "                                 ))\n",
    "\n",
    "\n",
    "    if TrainMapsOut:\n",
    "        assert refined_labels_directory is not None, 'Directory for output of refined Maps needs to be specified'\n",
    "        #Create Output Directories\n",
    "        path_train = refined_labels_directory\n",
    "        path_plain = join(path_train, 'PlainMaps/')\n",
    "        path_CRF = join(path_train, 'CRFMaps/')\n",
    "        path_MVA = join(path_train, 'MVAMaps/')\n",
    "        for path in  [path_train,path_plain,path_CRF,path_MVA]:\n",
    "            os.makedirs(path,exist_ok=True)\n",
    "        name = train_loader.dataset.image_list # the order is kept correctly, 0...2499\n",
    "\n",
    "        save_compute_crf(path_plain, path_CRF, path_MVA,\n",
    "                           name, gt_targets, pseudo_targets, raw_preds, mva_preds,\n",
    "                           image2indx,\n",
    "                           DOC_plain, DOC_CRF, DOC_MVA,\n",
    "                           args)\n",
    "\n",
    "        assert mva_preds.sum()!=0, 'mva_preds was not updated!?'\n",
    "\n",
    "        logger.info('\\n\\n\\nTraining Maps Extracted in this epoch {}. Results:\\n\\nPlain:{}\\nCRF:{}\\nMVA:{}'\\\n",
    "            .format(epoch, str(DOC_plain), str(DOC_CRF), str(DOC_MVA)))\n",
    "\n",
    "        DOC_plain.write_history(refined_labels_directory + \"Results_plain.txt\")\n",
    "        DOC_CRF.write_history(refined_labels_directory + \"Results_CRF.txt\")\n",
    "        DOC_MVA.write_history(refined_labels_directory + \"Results_MVA.txt\")\n",
    "\n",
    "    else:\n",
    "        DOC.write_history(doc_directory + \"loss_train.txt\")\n",
    "\n",
    "    return losses.avg, mva_preds\n",
    "\n",
    "def train_round(args, target_dirs, output_dir_it, discretization_threshold, MapsOut = False):\n",
    "    log_handler = logging.FileHandler(output_dir_it+'/log.txt')\n",
    "    logger.addHandler(log_handler)\n",
    "    batch_size = args.batch_size\n",
    "    num_workers = args.workers\n",
    "    crop_size = args.crop_size\n",
    "\n",
    "    iter_size_train=args.iter_size\n",
    "\n",
    "    f=open(output_dir_it + \"params.txt\", \"w\")\n",
    "    f.write(\"Parameters:\\n\\n\")\n",
    "    for k, v in args.__dict__.items():\n",
    "        f.write(\"{}:\\t\\t{}\\n\".format(k, v))\n",
    "    f.close()\n",
    "\n",
    "    single_model1 = DRNSeg(args.arch, 2, None, pretrained=True)\n",
    "    single_model2 = DRNSeg(args.arch, 2, None, pretrained=True)\n",
    "\n",
    "    #load pretrained model for layers that match in size.\n",
    "    if args.pretrained:\n",
    "        print('Loading model 1 state dict\\n')\n",
    "        load_dict=torch.load(args.pretrained)\n",
    "        own_dict=single_model1.state_dict()\n",
    "        for name, param in load_dict.items():\n",
    "            if name not in own_dict:\n",
    "                warnings.warn(' Model could not be loaded ! Thats bad ! ')\n",
    "                continue\n",
    "            if own_dict[name].size() != load_dict[name].size():\n",
    "                print('Size of pretrained model and your model does not match in {} ({} vs. {}). Layer stays initialized randomly.'\\\n",
    "                    .format(name, own_dict[name].size(), load_dict[name].size()))\n",
    "            else:\n",
    "                own_dict[name].copy_(param)\n",
    "        print('Loading model 2 state dict\\n')\n",
    "        load_dict=torch.load(args.pretrained)\n",
    "        own_dict=single_model2.state_dict()\n",
    "        for name, param in load_dict.items():\n",
    "            if name not in own_dict:\n",
    "                warnings.warn(' Model could not be loaded ! Thats bad ! ')\n",
    "                continue\n",
    "            if own_dict[name].size() != load_dict[name].size():\n",
    "                print('Size of pretrained model and your model does not match in {} ({} vs. {}). Layer stays initialized randomly.'\\\n",
    "                    .format(name, own_dict[name].size(), load_dict[name].size()))\n",
    "            else:\n",
    "                own_dict[name].copy_(param)\n",
    "        print('\\n')\n",
    "\n",
    "    model1 = torch.nn.DataParallel(single_model1.cuda())\n",
    "    model2 = torch.nn.DataParallel(single_model2.cuda())\n",
    "\n",
    "    # Data loading code\n",
    "    data_dir = args.data_dir\n",
    "    info = json.load(open(join(data_dir, 'info.json'), 'r'))\n",
    "    normalize = transforms.Normalize(mean=info['mean'],\n",
    "                                     std=info['std'])\n",
    "    t = []\n",
    "    t.extend([transforms.Resize_Image(crop_size),\n",
    "              transforms.ToTensor(),\n",
    "              normalize])\n",
    "    t_val = t\n",
    "\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        SegList(args, data_dir, 'train', transforms.Compose(t),\n",
    "        image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "        targets = target_dirs, list_dir=args.data_dir, out_name=True),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "        pin_memory=True, drop_last=True\n",
    "     )\n",
    "\n",
    "    if not MapsOut:\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            SegList(args, data_dir, 'val', transforms.Compose(t_val),\n",
    "            image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "            targets = None, list_dir=args.data_dir, out_name=True),\n",
    "            batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "            pin_memory=True, drop_last=True\n",
    "        )\n",
    "\n",
    "    optimizer1 = torch.optim.Adam(single_model1.optim_parameters(), lr=args.lr)\n",
    "    optimizer2 = torch.optim.Adam(single_model2.optim_parameters(), lr=args.lr)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    start_epoch = 0\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume_model1:\n",
    "        if os.path.isfile(args.resume_model1):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume_model1))\n",
    "            checkpoint = torch.load(args.resume_model1)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            model1.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer1.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume_model1, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume_model1))\n",
    "\n",
    "    if args.resume_model2:\n",
    "        if os.path.isfile(args.resume_model2):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume_model2))\n",
    "            checkpoint = torch.load(args.resume_model2)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            model2.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer2.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume_model2, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume_model2))\n",
    "\n",
    "\n",
    "    mva_preds,image2indx = init_mva_preds(args,train_loader)\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        lr = adjust_learning_rate(args, optimizer1, epoch)\n",
    "        lr = adjust_learning_rate(args, optimizer2, epoch)\n",
    "        logger.info('Epoch: [{0}]\\tlr {1:.2e}'.format(epoch, lr))\n",
    "\n",
    "        if epoch < args.warm_up:\n",
    "            print('Warmup Net1')\n",
    "            trainloss, mva_preds = warmup( train_loader,\n",
    "                                model1,\n",
    "                                optimizer1,\n",
    "                                epoch,\n",
    "                                output_dir_it,\n",
    "                                args,\n",
    "                                discretization_threshold,\n",
    "                                refined_labels_directory=output_dir_it,\n",
    "                                iter_size=iter_size_train,\n",
    "                                print_freq=2,\n",
    "                                TrainMapsOut=MapsOut,\n",
    "                                mva_preds=mva_preds,\n",
    "                                image2indx=image2indx)\n",
    "            assert torch.isnan(mva_preds.sum(dim=(1,2))).sum().item() == 0, 'images are droped since size of data set is not a multiple of batch size'\n",
    "            print('Warmup Net2')\n",
    "            trainloss, mva_preds = warmup( train_loader,\n",
    "                                model2,\n",
    "                                optimizer2,\n",
    "                                epoch,\n",
    "                                output_dir_it,\n",
    "                                args,\n",
    "                                discretization_threshold,\n",
    "                                refined_labels_directory=output_dir_it,\n",
    "                                iter_size=iter_size_train,\n",
    "                                print_freq=2,\n",
    "                                TrainMapsOut=MapsOut,\n",
    "                                mva_preds=mva_preds,\n",
    "                                image2indx=image2indx)\n",
    "            assert torch.isnan(mva_preds.sum(dim=(1,2))).sum().item() == 0, 'images are droped since size of data set is not a multiple of batch size'\n",
    "        else:\n",
    "            print('Eval Train Net1')\n",
    "            prob1  = eval_train( train_loader,\n",
    "                   model1,\n",
    "                   epoch,\n",
    "                   output_dir_it,\n",
    "                   args,\n",
    "                   discretization_threshold,\n",
    "                   refined_labels_directory=output_dir_it,\n",
    "                   iter_size=iter_size_train,\n",
    "                   print_freq=2,\n",
    "                   TrainMapsOut=MapsOut,\n",
    "                   mva_preds=mva_preds,\n",
    "                   image2indx=image2indx)\n",
    "            assert torch.isnan(mva_preds.sum(dim=(1,2))).sum().item() == 0, 'images are droped since size of data set is not a multiple of batch size'\n",
    "\n",
    "\n",
    "            print('Eval Train Net2')\n",
    "            prob2 = eval_train( train_loader,\n",
    "                    model2,\n",
    "                    epoch,\n",
    "                    output_dir_it,\n",
    "                    args,\n",
    "                    discretization_threshold,\n",
    "                    refined_labels_directory=output_dir_it,\n",
    "                    iter_size=iter_size_train,\n",
    "                    print_freq=2,\n",
    "                    TrainMapsOut=MapsOut,\n",
    "                    mva_preds=mva_preds,\n",
    "                    image2indx=image2indx)\n",
    "            assert torch.isnan(mva_preds.sum(dim=(1,2))).sum().item() == 0, 'images are droped since size of data set is not a multiple of batch size'\n",
    "            \n",
    "            #remove me ablation_1_labeled\n",
    "            #prob1 = torch.ones(2500)\n",
    "            #prob2 = torch.ones(2500)\n",
    "\n",
    "            pred1 = (prob1 > args.p_threshold)\n",
    "            pred2 = (prob2 > args.p_threshold)\n",
    "            \n",
    "            pred1 = torch.from_numpy(pred1)\n",
    "            pred2 = torch.from_numpy(pred2)\n",
    "\n",
    "            labeled_train_loader = torch.utils.data.DataLoader(\n",
    "                    SegList(args, data_dir, 'labeled', transforms.Compose(t),\n",
    "                    image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "                    targets = target_dirs, list_dir=args.data_dir, out_name=True,\n",
    "                    pred = pred2, prob = prob2),\n",
    "                    batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                    pin_memory=True, drop_last=True\n",
    "                 )\n",
    "            #pdb.set_trace()\n",
    "            unlabeled_train_loader = torch.utils.data.DataLoader(\n",
    "                    SegList(args, data_dir, 'unlabeled', transforms.Compose(t),\n",
    "                    image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "                    targets = target_dirs, list_dir=args.data_dir, out_name=True,\n",
    "                    pred = pred2, prob = prob2),\n",
    "                    batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                    pin_memory=True, drop_last=True\n",
    "                    )\n",
    "            \n",
    "            print('Training Net1')\n",
    "            trainloss, mva_preds = train(labeled_train_loader,\n",
    "                                unlabeled_train_loader,\n",
    "                                model1,\n",
    "                                model2,\n",
    "                                optimizer1,\n",
    "                                epoch,\n",
    "                                output_dir_it,\n",
    "                                args,\n",
    "                                discretization_threshold,\n",
    "                                refined_labels_directory=output_dir_it,\n",
    "                                iter_size=iter_size_train,\n",
    "                                print_freq=3,\n",
    "                                TrainMapsOut=MapsOut,\n",
    "                                mva_preds=mva_preds,\n",
    "                                image2indx=image2indx)\n",
    "            assert torch.isnan(mva_preds.sum(dim=(1,2))).sum().item() == 0, 'images are droped since size of data set is not a multiple of batch size'\n",
    "\n",
    "            labeled_train_loader = torch.utils.data.DataLoader(\n",
    "                SegList(args, data_dir, 'labeled', transforms.Compose(t),\n",
    "                image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "                targets = target_dirs, list_dir=args.data_dir, out_name=True,\n",
    "                pred = pred1, prob = prob1),\n",
    "                batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                pin_memory=True, drop_last=True\n",
    "             )\n",
    "            \n",
    "            unlabeled_train_loader = torch.utils.data.DataLoader(\n",
    "                SegList(args, data_dir, 'unlabeled', transforms.Compose(t),\n",
    "                image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "                targets = target_dirs, list_dir=args.data_dir, out_name=True,\n",
    "                pred = pred1, prob = prob1),\n",
    "                batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                pin_memory=True, drop_last=True\n",
    "             )\n",
    "\n",
    "            print('Training Net2')\n",
    "            trainloss, mva_preds = train(labeled_train_loader,\n",
    "                                unlabeled_train_loader,\n",
    "                                model2,\n",
    "                                model1,\n",
    "                                optimizer2,\n",
    "                                epoch,\n",
    "                                output_dir_it,\n",
    "                                args,\n",
    "                                discretization_threshold,\n",
    "                                refined_labels_directory=output_dir_it,\n",
    "                                iter_size=iter_size_train,\n",
    "                                print_freq=3,\n",
    "                                TrainMapsOut=MapsOut,\n",
    "                                mva_preds=mva_preds,\n",
    "                                image2indx=image2indx)\n",
    "            assert torch.isnan(mva_preds.sum(dim=(1,2))).sum().item() == 0, 'images are droped since size of data set is not a multiple of batch size'\n",
    "            if not MapsOut:\n",
    "                val_loader = torch.utils.data.DataLoader(\n",
    "                    SegList(args, data_dir, 'val', transforms.Compose(t_val),\n",
    "                    image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "                    targets = None, list_dir=args.data_dir, out_name=True),\n",
    "                    batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                    pin_memory=True, drop_last=True\n",
    "                    )\n",
    "\n",
    "                # evaluate on validation set\n",
    "                print('Validation Net1')\n",
    "                F_beta, GT_loss_L1 = validate(val_loader, model1, epoch, output_dir_it, args, print_freq=6)\n",
    "                print('Validation Net2')\n",
    "                F_beta, GT_loss_L1 = validate(val_loader, model2, epoch, output_dir_it, args, print_freq=6)\n",
    "\n",
    "            checkpoint_model1_path_latest = output_dir_it + 'checkpoint_model1_{:03d}.pth.tar'.format(epoch + 1)\n",
    "            checkpoint_model2_path_latest = output_dir_it + 'checkpoint_model2_{:03d}.pth.tar'.format(epoch + 1)\n",
    "\n",
    "            if (epoch + 1) % args.checkpoint_freq == 0 or epoch==args.epochs:\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'arch': args.arch,\n",
    "                    'state_dict': model1.state_dict(),\n",
    "                    'optimizer' : optimizer1.state_dict(),\n",
    "                }, checkpoint_model1_path_latest)\n",
    "            if (epoch + 1) % args.checkpoint_freq == 0 or epoch==args.epochs:\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'arch': args.arch,\n",
    "                    'state_dict': model2.state_dict(),\n",
    "                    'optimizer' : optimizer2.state_dict(),\n",
    "                }, checkpoint_model2_path_latest)\n",
    "\n",
    "    return trainloss\n",
    "\n",
    "def test(args, eval_data_loader, model, num_classes,\n",
    "          output_dir='pred', save_vis=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        end = time.time()\n",
    "        hist = np.zeros((num_classes, num_classes))\n",
    "\n",
    "        DOC = Trackometer(0)\n",
    "\n",
    "        f = open(output_dir + 'Results.txt', 'w')\n",
    "        for i, (image, GT_label, pseudolabels, name) in enumerate(eval_data_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "            #====================================================================================================================\n",
    "            #       Get Image Names\n",
    "            #====================================================================================================================\n",
    "\n",
    "            #Get image name without path\n",
    "            imname = [(path.split('/')[-1])[:-4] + '.png' for path in name]\n",
    "            #====================================================================================================================\n",
    "            #make target float and normalize to range [0,1] for each pixel\n",
    "            GT_label=GT_label.float()/torch.max(GT_label).item()\n",
    "            for dummy_ind in range(len(pseudolabels)):\n",
    "                pseudolabels[dummy_ind]=pseudolabels[dummy_ind].float()/255.0\n",
    "\n",
    "            #pad the image, s.t. width and height are both multiples of 8.\n",
    "            #This way, the output will have the same shape as the image. The padded part will be thrown away in the output.\n",
    "            #Get original width and height\n",
    "            w0=image.shape[2]\n",
    "            h0=image.shape[3]\n",
    "            #Get new width, height, that is a multiple of n=8\n",
    "            n=8\n",
    "            dw = -w0%n\n",
    "            dh = -h0%n\n",
    "            w1 = w0+dw\n",
    "            h1 = h0+dh\n",
    "            #pad on the right the missing width and on the bottom the missing height.\n",
    "            pad_reflection=nn.ReflectionPad2d((0,dh,0,dw))\n",
    "            im_new=pad_reflection(image)\n",
    "            #check if padding went well.\n",
    "            assert torch.all(torch.eq(image,im_new[:,:,:w0,:h0]))\n",
    "\n",
    "            image_var = Variable(im_new, requires_grad=False)\n",
    "\n",
    "            final = model(image_var)[0]\n",
    "            _, pred = torch.max(final, 1)\n",
    "\n",
    "            #make continuous prediction, then cast it to unit8\n",
    "            m=torch.nn.Softmax(dim=1)\n",
    "            sal_pred=m(final)\n",
    "            if args.DCRF:\n",
    "                sal_pred=apply_dcrf(sal_pred[:,:,:w0,:h0], name, Color=(args.DCRF=='Color' or args.DCRF=='color'))\n",
    "            else:\n",
    "                sal_pred=sal_pred[:, 0, :w0, :h0]\n",
    "\n",
    "            assert sal_pred.shape==GT_label.shape\n",
    "\n",
    "            DOC.update(sal_pred, GT_label.cuda(), [sal_pred], [GT_label.cuda()])\n",
    "            #DOC.update(sal_pred, GT_label, [sal_pred], [GT_label])\n",
    "\n",
    "\n",
    "            sal_pred = (sal_pred*255).int().cpu().data.numpy()\n",
    "            GT_label = (GT_label*255).int().cpu().data.numpy()\n",
    "\n",
    "            if save_vis:\n",
    "                save_output_images(sal_pred, imname, output_dir)\n",
    "                save_output_images(GT_label, imname, output_dir, name_suffix='_GT')\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "\n",
    "            end = time.time()\n",
    "            if i%50 == 0:\n",
    "                logger.info('Eval: [{0}/{1}]\\t'\n",
    "                            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                            'L1 {L1.val:.3f} ({L1.avg:.3f})\\t'\n",
    "                            'F-measure {F.val:.3f} ({F.avg:.3f})\\t'\n",
    "                            .format(i, len(eval_data_loader), batch_time=batch_time, data_time=data_time, L1=DOC.L1_GT, F=DOC.F_GT))\n",
    "\n",
    "            f.write('{}\\t{}\\t{}\\t{}\\n'.format(DOC.L1_GT.val, DOC.F_GT.val, DOC.prec_GT.val, DOC.recall_GT.val))\n",
    "\n",
    "        f.close()\n",
    "        print(DOC)\n",
    "\n",
    "        return DOC\n",
    "\n",
    "\n",
    "def test_saliency(args):\n",
    "    batch_size = args.batch_size\n",
    "    num_workers = args.workers\n",
    "    test_dir = join(args.root_dir, 'Doc/Test/')\n",
    "\n",
    "    for k, v in args.__dict__.items():\n",
    "        print(k, ':', v)\n",
    "\n",
    "    single_model = DRNSeg(args.arch, 2, pretrained_model=None, pretrained=True)\n",
    "    model = torch.nn.DataParallel(single_model).cuda()\n",
    "\n",
    "    data_dir = args.data_dir\n",
    "    info = json.load(open(join(data_dir, 'info.json'), 'r'))\n",
    "    normalize = transforms.Normalize(mean=info['mean'], std=info['std'])\n",
    "\n",
    "    dataset = SegList_test(args, data_dir, 'test', transforms.Compose([\n",
    "        transforms.Resize_Image(args.crop_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), image_dir= join(args.root_dir, 'Data/01_img/'), gt_dir= join(args.root_dir, 'Data/02_gt/'),\n",
    "    list_dir=args.data_dir, out_name=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "        pin_memory=False\n",
    "    )\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    if not args.resume_model1:\n",
    "        args.resume_model1 = join(args.root_dir + 'Doc/Phase_II_Fusion/checkpoint_model1_125.pth.tar')\n",
    "    start_epoch = 0\n",
    "    if args.resume_model1:\n",
    "        if os.path.isfile(args.resume_model1):\n",
    "            logger.info(\"=> loading checkpoint '{}'\".format(args.resume_model1))\n",
    "            checkpoint = torch.load(args.resume_model1)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            logger.info(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume_model1, checkpoint['epoch']))\n",
    "        else:\n",
    "            logger.info(\"=> no checkpoint found at '{}'\".format(args.resume_model1))\n",
    "\n",
    "    if not exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    DOC = test(args, test_loader, model, 2, save_vis=True, output_dir=test_dir)\n",
    "\n",
    "    logger.info('MAE = %f', DOC.L1_GT.avg)\n",
    "\n",
    "    return DOC\n",
    "\n",
    "\n",
    "\n",
    "def test_all_datasets(args):\n",
    "    #for each dataset, we have a dictionary, that contains\n",
    "    #   - the name\n",
    "    #   - the Parameters directory\n",
    "    #   - name of data (***_names.txt file in Param directory)\n",
    "    #   - the batch size for testing\n",
    "    test_dir = join(args.root_dir, 'Doc/Test_all/')\n",
    "    if not exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    datasets = []\n",
    "\n",
    "    MSRAB = ECSSD = DUT = SED2 = THUR = False\n",
    "\n",
    "    MSRAB = True\n",
    "    ECSSD = True\n",
    "    DUT = True\n",
    "    '''\n",
    "    SED2 = True\n",
    "    THUR = True\n",
    "    '''\n",
    "    if not args.resume_model1:\n",
    "        args.resume_model1 = join(args.root_dir + 'Doc/Phase_II_Fusion/checkpoint_model1_125.pth.tar')\n",
    "\n",
    "    #01_MSRAB\n",
    "    if MSRAB:\n",
    "        datasets.append({ \\\n",
    "                'name' : '01_MSRAB', \\\n",
    "                'param_dir' : '/notebooks/deepdividemix/Data/01_MSRAB/Parameters/', \\\n",
    "                'data_prefix' : 'test', \\\n",
    "                'batch_size' : 1 \\\n",
    "                })\n",
    "    #02_ECSSD\n",
    "    if ECSSD:\n",
    "        datasets.append({ \\\n",
    "                'name' : '02_ECSSD', \\\n",
    "                'param_dir' : '/notebooks/deepdividemix/Data/02_ECSSD/Parameters/', \\\n",
    "                'data_prefix' : 'all', \\\n",
    "                'batch_size' : 1 \\\n",
    "                })\n",
    "\n",
    "    #03_DUT\n",
    "    if DUT:\n",
    "        datasets.append({ \\\n",
    "                'name' : '03_DUT', \\\n",
    "                'param_dir' : '/notebooks/deepdividemix/Data/03_DUT/Parameters/', \\\n",
    "                'data_prefix' : 'all', \\\n",
    "                'batch_size' : 1 \\\n",
    "                })\n",
    "\n",
    "    #04_SED2\n",
    "    if SED2:\n",
    "        datasets.append({ \\\n",
    "                'name' : '04_SED2', \\\n",
    "                'param_dir' : '/media/bigData/_80_User/Dax/UnsupSD/SD_beta/Data/04_SED2/Parameters/', \\\n",
    "                'data_prefix' : 'all', \\\n",
    "                'batch_size' : 1 \\\n",
    "                })\n",
    "\n",
    "    #06_THUR\n",
    "    if THUR:\n",
    "        datasets.append({ \\\n",
    "                'name' : '06_THUR', \\\n",
    "                'param_dir' : '/media/bigData/_80_User/Dax/UnsupSD/SD_beta/Data/06_THUR/Parameters/', \\\n",
    "                'data_prefix' : 'GT', \\\n",
    "                'batch_size' : 1 \\\n",
    "                })\n",
    "\n",
    "    #Iterate through the dictionaries and test each dataset\n",
    "    for dataset in datasets:\n",
    "        #set correct arguments\n",
    "        args.dataset_name = dataset['name']\n",
    "        args.data_dir = dataset['param_dir']\n",
    "        args.test_data = dataset['data_prefix']\n",
    "        args.batch_size = dataset['batch_size']\n",
    "        DOC = test_saliency(args)\n",
    "        dataset['Result'] = DOC\n",
    "\n",
    "    print(\"\\n\\n\\t\\t\\tMAE\\t\\tF\\t\\tprecision\\trecall\")\n",
    "    for dataset in datasets:\n",
    "        print(\"{name}: \\t\\t{DOC.L1_GT.avg:.3f}\\t\\t{DOC.F_GT.avg:.3f}\\t\\t{DOC.prec_GT.avg:.3f}\\t\\t{DOC.recall_GT.avg:.3f}\"\\\n",
    "            .format(name=dataset['name'], DOC=dataset['Result']) )\n",
    "\n",
    "\n",
    "    result_file = join(test_dir, 'Test_Results.txt')\n",
    "    f = open(result_file, 'a')\n",
    "    f.write(\"\\t\\t\\tMAE\\t\\tF\\t\\tprecision\\trecall\\n\")\n",
    "    for dataset in datasets:\n",
    "        f.write(\"{name}: \\t\\t{DOC.L1_GT.avg:.5f}\\t\\t{DOC.F_GT.avg:.5f}\\t\\t{DOC.prec_GT.avg:.5f}\\t\\t{DOC.recall_GT.avg:.5f}\\n\"\\\n",
    "            .format(name=dataset['name'], DOC=dataset['Result']) )\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_unsupervised(args):\n",
    "    #====================================================================================================================\n",
    "    #       Phase I: Refinement of Pseodulabels\n",
    "    #====================================================================================================================.\n",
    "    #learning_rates_refinement = [1e-6, 2e-6, 5e-6]\n",
    "    learning_rates_refinement = [1e-6, 2e-6]\n",
    "    args.beta_sq = 1.0\n",
    "    args.epochs = 25\n",
    "    args.iter_size = min(1, int(40/args.batch_size))\n",
    "    num_iterations_refinement = len(learning_rates_refinement)\n",
    "    doc_directory = join(args.root_dir, 'Doc/')\n",
    "    refined_labels_directory = join(doc_directory, 'Phase_I_Refined_Maps/')\n",
    "    os.makedirs(doc_directory, exist_ok=True)\n",
    "    os.makedirs(refined_labels_directory, exist_ok=True)\n",
    "    pseudolabels = [\n",
    "        {'name': 'MC', 'data_directory': join(args.root_dir, 'Data/03_mc/'), 'discretization_threshold': 0.31, \\\n",
    "            'F-score_plain': [71.65], 'MAE_plain': [14.41], 'F-score_mva': [71.65], 'MAE_mva': [14.41]},\n",
    "        {'name': 'HS', 'data_directory': join(args.root_dir, 'Data/04_hs/'), 'discretization_threshold': 0.36, \\\n",
    "            'F-score_plain': [71.29], 'MAE_plain': [16.09], 'F-score_mva': [71.29], 'MAE_mva': [16.09]},\n",
    "        {'name': 'DSR', 'data_directory': join(args.root_dir, 'Data/05_dsr/'), 'discretization_threshold': 0.23, \\\n",
    "            'F-score_plain': [72.27], 'MAE_plain': [12.07], 'F-score_mva': [72.27], 'MAE_mva': [12.07]},\n",
    "        {'name': 'RBD', 'data_directory': join(args.root_dir, 'Data/06_rbd/'), 'discretization_threshold': 0.25, \\\n",
    "            'F-score_plain': [75.08], 'MAE_plain': [11.71], 'F-score_mva': [75.08], 'MAE_mva': [11.71]}\n",
    "    ]\n",
    "    target_dirs_refined = []\n",
    "    for pseudolabel in pseudolabels:\n",
    "        #directory with input targets\n",
    "        target_dir = [pseudolabel['data_directory']]\n",
    "        #directory for output targets\n",
    "        output_dir = join(refined_labels_directory, pseudolabel['name'] + '/')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        #discretization threshold for this particular pseudolabel\n",
    "        discretization_threshold = pseudolabel['discretization_threshold']\n",
    "        for i in range(num_iterations_refinement):\n",
    "            args.lr = learning_rates_refinement[i]\n",
    "            #output directory for current iteration\n",
    "            output_dir_it = join(output_dir, 'Iteration_' + str(i+1) + '/')\n",
    "            os.makedirs(output_dir_it, exist_ok=True)\n",
    "            #train_round(args, target_dir, output_dir_it, discretization_threshold, MapsOut = True)\n",
    "            #after one iteration, discretization threshold does not matter too much\n",
    "            discretization_threshold = 0.5\n",
    "            target_dir = [join(output_dir_it, 'MVAMaps/')]\n",
    "            #get Results\n",
    "            #update_plots(refined_labels_directory, output_dir_it, pseudolabel)\n",
    "        target_dirs_refined.append(target_dir[0])\n",
    "\n",
    "    #====================================================================================================================\n",
    "    #       Phase II: Fusion of refine Pseudolabels\n",
    "    #====================================================================================================================\n",
    "    phase_2_directory = join(doc_directory, 'Phase_II_Fusion/')\n",
    "    os.makedirs(phase_2_directory, exist_ok=True)\n",
    "    args.epochs = 200\n",
    "    args.beta_sq = 4.0\n",
    "    args.lr = 1e-4\n",
    "    args.iter_size = min(1, int(100/args.batch_size))\n",
    "    train_round(args, target_dirs_refined, phase_2_directory, 0.5, MapsOut = False)\n",
    "\n",
    "    create_phase2_plots(phase_2_directory)\n",
    "\n",
    "def main():\n",
    "    args = SimpleNamespace(arch='drn_d_22', batch_size=8\\\n",
    "                           , beta_sq=1.0, bn_sync=False, checkpoint_freq=25\\\n",
    "                           , cmd='train'\\\n",
    "                           , crop_size=432\\\n",
    "                           , data_dir='/notebooks/deepdividemix/Parameters/'\\\n",
    "                           , pretrained='/notebooks/deepdividemix/Pretrained_Models/drn_pretraining/drn_d_22_cityscapes.pth'\\\n",
    "                           , iter_size=1 \\\n",
    "                           , root_dir='/notebooks/deepdividemix/' \\\n",
    "                           , resume_model1='/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model1_125.pth.tar' \\\n",
    "                           , resume_model2='/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model2_125.pth.tar' \\\n",
    "                           , warm_up=1 \\\n",
    "                           , p_threshold=0.85 \\\n",
    "                           , T=0.5 \\\n",
    "                           , alpha=4 \\\n",
    "                           , DCRF=None \\\n",
    "                           , lambda_u=25 \\\n",
    "                           , workers=0)\n",
    "    \n",
    "    if args.cmd == 'train':\n",
    "         '''if os.path.isdir(join(args.root_dir, 'Doc')):\n",
    "             print(\"\\n\\n\\n\" + \"=\"*100 + \"\\n\\n\\t\\tWarning! This doc path seems to be used!\\n\\t\\tPress \\\"c\\\" to continue and overwrite existing files, \\\"exit\\\" to abort.\\n\\n\" + \"=\"*100 + \"\\n\\n\\n\")\n",
    "             pdb.set_trace()'''\n",
    "         train_unsupervised(args)\n",
    "\n",
    "    elif args.cmd == 'test':\n",
    "        args.dataset_name='01_MSRAB'\n",
    "        test_saliency(args)\n",
    "\n",
    "    elif args.cmd == 'test_all':\n",
    "        test_all_datasets(args)\n",
    "'''                           \n",
    ", resume_model1='/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model1_100.pth.tar' \\\n",
    "                           , resume_model2='/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model2_100.pth.tar' \\\n",
    "                           , resume_model1='' \\\n",
    "                           , resume_model2='' \\\n",
    "\n",
    "                           \n",
    "                           '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caring-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_rampup(current, warm_up, rampup_length=16):\n",
    "     current = np.clip((current-warm_up) / rampup_length, 0.0, 1.0)\n",
    "     return 25*float(current)\n",
    "\n",
    "class SemiLoss(object):\n",
    "    def __call__(self, outputs_x, targets_x, outputs_u, targets_u, epoch, warm_up):\n",
    "        probs_u = torch.softmax(outputs_u, dim=1)\n",
    "        #Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1))\n",
    "        Lu = torch.mean((probs_u - targets_u)**2)\n",
    "\n",
    "        return Lu, linear_rampup(epoch,warm_up)\n",
    "\n",
    "criterion = SemiLoss()\n",
    "\n",
    "def train(labeled_train_loader, unlabeled_train_loader, model1, model2, optimizer, epoch, doc_directory, args, discretization_threshold, refined_labels_directory=None, iter_size=5, print_freq=10, TrainMapsOut=False,mva_preds=None,image2indx=None):\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    batch_size = args.batch_size\n",
    "\n",
    "    DOC=Trackometer(epoch)\n",
    "    if TrainMapsOut:\n",
    "        DOC_plain = Trackometer(epoch)\n",
    "        DOC_CRF = Trackometer(epoch)\n",
    "        DOC_MVA = Trackometer(epoch)\n",
    "\n",
    "    Disc_Thr = discretization_threshold\n",
    "\n",
    "    # switch to train mode\n",
    "    model1.train()\n",
    "    model2.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    unlabeled_train_iter = iter(unlabeled_train_loader)\n",
    "    num_iter = (len(labeled_train_loader.dataset)//batch_size)+1\n",
    "\n",
    "    output_shape = mva_preds.shape\n",
    "    raw_preds  = torch.zeros((output_shape[0],2,output_shape[1],output_shape[2]))\n",
    "    gt_targets =  torch.zeros((mva_preds.shape))\n",
    "    pseudo_targets =  torch.zeros((mva_preds.shape))\n",
    "\n",
    "    unlabeled_dataloader_empty = False\n",
    "    #unlabeled_dataloader_empty = True #Removeme\n",
    "\n",
    "    Lu = 0\n",
    "    for i, (index_x, Data_x, w_x) in tqdm(enumerate(labeled_train_loader)):\n",
    "        if not unlabeled_dataloader_empty:\n",
    "            try:\n",
    "                index_u, Data_u = unlabeled_train_iter.next()\n",
    "\n",
    "                #UnLabeled data procesing start here\n",
    "                data_time.update(time.time() - end)\n",
    "                #initialize batch data\n",
    "                batch_data_unlabeled_net1=BatchData(Data_u, active=True)\n",
    "                batch_data_unlabeled_net2=BatchData(Data_u, active=True)\n",
    "                #check dimensions of labels\n",
    "                batch_data_unlabeled_net1.check_dimension()\n",
    "                batch_data_unlabeled_net2.check_dimension()\n",
    "\n",
    "                batch_data_unlabeled_net1.create_vars_on_cuda()\n",
    "                batch_data_unlabeled_net2.create_vars_on_cuda()\n",
    "        \n",
    "                batch_data_unlabeled_net1.compute_saliency(model1, False)\n",
    "                batch_data_unlabeled_net2.compute_saliency(model2, False)\n",
    "    \n",
    "                outputs_u1 = batch_data_unlabeled_net1.sal_pred        \n",
    "                outputs_u2 = batch_data_unlabeled_net2.sal_pred\n",
    "                        \n",
    "                pu = (outputs_u1 + outputs_u2) / 2\n",
    "            \n",
    "                ptu = pu**(1/args.T) # temparature sharpening\n",
    "                #pdb.set_trace()\n",
    "\n",
    "                #targets_u = F.normalize(ptu)\n",
    "                targets_u = ptu\n",
    "\n",
    "                for dummy_ind in range(len(batch_data_unlabeled_net1.pseudolabels_var)):\n",
    "                    batch_data_unlabeled_net1.pseudolabels_var[dummy_ind]=targets_u\n",
    "\n",
    "                batch_data_unlabeled_net1.compute_loss(beta=args.beta_sq)\n",
    "\n",
    "                Lu = batch_data_unlabeled_net1.loss\n",
    "\n",
    "            except:\n",
    "                # First time in here so set unlabeled dataloader to empty\n",
    "                Lu = 0\n",
    "                unlabeled_dataloader_empty = True\n",
    "\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        #Labeled data procesing start here\n",
    "        w_x = w_x.view(-1,1).type(torch.FloatTensor).cuda()\n",
    "        #initialize batch data\n",
    "        #pdb.set_trace()\n",
    "        batch_data_labeled_net1=BatchData(Data_x, active=True)\n",
    "        batch_data_labeled_net2=BatchData(Data_x, active=True)\n",
    "        #check dimensions of labels\n",
    "        batch_data_labeled_net1.check_dimension()\n",
    "        batch_data_labeled_net2.check_dimension()\n",
    "        #Make GT label and pseudolabels float and normalize to range [0,1]\n",
    "        #pdb.set_trace()\n",
    "        batch_data_labeled_net1.normalize_labels()\n",
    "        #batch_data_labeled_net2.normalize_labels()\n",
    "        #Push input to cuda. Create Variables for input and labels.\n",
    "        #batch_data.create_vars_on_cuda()\n",
    "        batch_data_labeled_net1.create_vars_on_cuda()\n",
    "        batch_data_labeled_net2.create_vars_on_cuda()\n",
    "\n",
    "        batch_data_labeled_net1.compute_saliency(model1, False)\n",
    "        batch_data_labeled_net2.compute_saliency(model2, False)\n",
    "\n",
    "        outputs_x1 = batch_data_labeled_net1.sal_pred\n",
    "        outputs_x2 = batch_data_labeled_net2.sal_pred\n",
    "\n",
    "        inputs_x = batch_data_labeled_net1.input_var\n",
    "\n",
    "        batch_data_labeled_net1.merge_pseudolabels()\n",
    "        labels_x = batch_data_labeled_net1.merged_labels\n",
    "            \n",
    "        px = (outputs_x1 + outputs_x2) / 2\n",
    "            \n",
    "        px = torch.stack([torch.add(torch.mul(w_x[i],labels_x[i]),torch.mul(1-w_x[i],px[i])) for i in range(len(w_x))])\n",
    "        ptx = px**(1/args.T) # temparature sharpening\n",
    "        #original targets_x = F.normalize(ptx)\n",
    "        targets_x = ptx\n",
    "        \n",
    "        for dummy_ind in range(len(batch_data_labeled_net1.pseudolabels_var)):\n",
    "            batch_data_labeled_net1.pseudolabels_var[dummy_ind]=targets_x\n",
    "\n",
    "        #pdb.set_trace()\n",
    "        batch_data_labeled_net1.discretize_pseudolabels(Disc_Thr)\n",
    "\n",
    "        batch_data_labeled_net1.compute_loss(beta=args.beta_sq)\n",
    "\n",
    "        Lx = batch_data_labeled_net1.loss\n",
    "\n",
    "        ll = len(labeled_train_loader)*batch_size\n",
    "        lu = len(unlabeled_train_loader)*batch_size\n",
    "        lamb = lu/ll\n",
    "        loss = Lx + lamb*Lu\n",
    "\n",
    "        FreqPrint=len(labeled_train_loader)//print_freq\n",
    "        if i % (FreqPrint) == 0:\n",
    "            logger.info('\\rEpoch [%3d] Iter[%3d/%3d]\\t Total loss: %.4f Labeled loss: %.4f Unlabeled Lu: %.4f lamb: %.4f len(unlabeled):%4d len(labeled): %4d'%(epoch, i+1, len(labeled_train_loader), loss, Lx, Lu, lamb, lu, ll))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "        \n",
    "    return losses.avg, mva_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 1 state dict\n",
      "\n",
      "Size of pretrained model and your model does not match in seg.weight (torch.Size([2, 512, 1, 1]) vs. torch.Size([19, 512, 1, 1])). Layer stays initialized randomly.\n",
      "Size of pretrained model and your model does not match in seg.bias (torch.Size([2]) vs. torch.Size([19])). Layer stays initialized randomly.\n",
      "Size of pretrained model and your model does not match in up.weight (torch.Size([2, 1, 16, 16]) vs. torch.Size([19, 1, 16, 16])). Layer stays initialized randomly.\n",
      "Loading model 2 state dict\n",
      "\n",
      "Size of pretrained model and your model does not match in seg.weight (torch.Size([2, 512, 1, 1]) vs. torch.Size([19, 512, 1, 1])). Layer stays initialized randomly.\n",
      "Size of pretrained model and your model does not match in seg.bias (torch.Size([2]) vs. torch.Size([19])). Layer stays initialized randomly.\n",
      "Size of pretrained model and your model does not match in up.weight (torch.Size([2, 1, 16, 16]) vs. torch.Size([19, 1, 16, 16])). Layer stays initialized randomly.\n",
      "\n",
      "\n",
      "=> loading checkpoint '/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model1_125.pth.tar'\n",
      "=> loaded checkpoint '/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model1_125.pth.tar' (epoch 125)\n",
      "=> loading checkpoint '/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model2_125.pth.tar'\n",
      "=> loaded checkpoint '/notebooks/deepdividemix/Doc/Phase_II_Fusion/checkpoint_model2_125.pth.tar' (epoch 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-28 19:36:09,865 <ipython-input-16-9719d6d3e8ec>:514 train_round] Epoch: [125]\tlr 4.14e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Train Net1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s][2021-10-28 19:36:12,928 <ipython-input-16-9719d6d3e8ec>:205 eval_train] Epoch: [125][0/312]\tTime 3.059 (3.059)\tData 2.137 (2.137)\tLoss 0.0348 (0.0348)\tL1 Loss GT 0.0356 (0.0356)\t\n",
      "156it [01:08,  2.38it/s][2021-10-28 19:37:20,643 <ipython-input-16-9719d6d3e8ec>:205 eval_train] Epoch: [125][156/312]\tTime 0.457 (0.451)\tData 0.282 (0.278)\tLoss 0.1656 (0.0760)\tL1 Loss GT 0.0730 (0.0626)\t\n",
      "312it [02:14,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Train Net2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s][2021-10-28 19:38:28,193 <ipython-input-16-9719d6d3e8ec>:205 eval_train] Epoch: [125][0/312]\tTime 1.245 (1.245)\tData 1.077 (1.077)\tLoss 0.0905 (0.0905)\tL1 Loss GT 0.0767 (0.0767)\t\n",
      "55it [00:18,  2.99it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from types import SimpleNamespace\n",
    "import torch.nn.functional as F\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-three",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
